[2023-07-21T15:49:39.010+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-21T15:49:39.018+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-21T15:49:39.018+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-07-21T15:49:39.018+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-07-21T15:49:39.018+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-07-21T15:49:39.028+0000] {taskinstance.py:1383} INFO - Executing <Task(HttpSensor): is_api_available> on 2023-07-20 00:00:00+00:00
[2023-07-21T15:49:39.033+0000] {standard_task_runner.py:55} INFO - Started process 14930 to run task
[2023-07-21T15:49:39.037+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'is_api_available', 'scheduled__2023-07-20T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmpw_ycw0t5']
[2023-07-21T15:49:39.039+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask is_api_available
[2023-07-21T15:49:39.121+0000] {task_command.py:376} INFO - Running <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [running]> on host 9d876987b8ed
[2023-07-21T15:49:39.199+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=is_api_available
AIRFLOW_CTX_EXECUTION_DATE=2023-07-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-20T00:00:00+00:00
[2023-07-21T15:49:39.200+0000] {http.py:120} INFO - Poking: api/
[2023-07-21T15:49:39.225+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/sensors/base.py", line 189, in execute
    poke_return = self.poke(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/sensors/http.py", line 135, in poke
    raise exc
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/sensors/http.py", line 126, in poke
    extra_options=self.extra_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/hooks/http.py", line 128, in run
    session = self.get_conn(headers)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/hooks/http.py", line 82, in get_conn
    conn = self.get_connection(self.http_conn_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/base.py", line 70, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/connection.py", line 432, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `user_api` isn't defined
[2023-07-21T15:49:39.229+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=user_processing, task_id=is_api_available, execution_date=20230720T000000, start_date=20230721T154939, end_date=20230721T154939
[2023-07-21T15:49:39.240+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 4 for task is_api_available (The conn_id `user_api` isn't defined; 14930)
[2023-07-21T15:49:39.290+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2023-07-21T15:49:39.320+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-07-22T05:54:18.707+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-22T05:54:18.752+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-22T05:54:18.766+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-07-22T05:54:18.769+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-07-22T05:54:18.770+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-07-22T05:54:18.803+0000] {taskinstance.py:1383} INFO - Executing <Task(HttpSensor): is_api_available> on 2023-07-20 00:00:00+00:00
[2023-07-22T05:54:18.821+0000] {standard_task_runner.py:55} INFO - Started process 5196 to run task
[2023-07-22T05:54:18.867+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'is_api_available', 'scheduled__2023-07-20T00:00:00+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmpd8pnd96i']
[2023-07-22T05:54:18.875+0000] {standard_task_runner.py:83} INFO - Job 55: Subtask is_api_available
[2023-07-22T05:54:19.032+0000] {task_command.py:376} INFO - Running <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [running]> on host ef71d3f52879
[2023-07-22T05:54:19.523+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=is_api_available
AIRFLOW_CTX_EXECUTION_DATE=2023-07-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-20T00:00:00+00:00
[2023-07-22T05:54:19.525+0000] {http.py:120} INFO - Poking: api/
[2023-07-22T05:54:19.651+0000] {base.py:71} INFO - Using connection ID 'user_api' for task execution.
[2023-07-22T05:54:19.690+0000] {http.py:148} INFO - Sending 'GET' to url: https://randomuser.me/api/
[2023-07-22T05:54:20.432+0000] {base.py:213} INFO - Success criteria met. Exiting.
[2023-07-22T05:54:20.486+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=is_api_available, execution_date=20230720T000000, start_date=20230722T055418, end_date=20230722T055420
[2023-07-22T05:54:20.702+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2023-07-22T05:54:20.880+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-07-22T05:56:59.039+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-22T05:56:59.053+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [queued]>
[2023-07-22T05:56:59.053+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-07-22T05:56:59.054+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-07-22T05:56:59.054+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-07-22T05:56:59.081+0000] {taskinstance.py:1383} INFO - Executing <Task(HttpSensor): is_api_available> on 2023-07-20 00:00:00+00:00
[2023-07-22T05:56:59.089+0000] {standard_task_runner.py:55} INFO - Started process 5488 to run task
[2023-07-22T05:56:59.096+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'is_api_available', 'scheduled__2023-07-20T00:00:00+00:00', '--job-id', '115', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmp4hv9twmt']
[2023-07-22T05:56:59.099+0000] {standard_task_runner.py:83} INFO - Job 115: Subtask is_api_available
[2023-07-22T05:56:59.212+0000] {task_command.py:376} INFO - Running <TaskInstance: user_processing.is_api_available scheduled__2023-07-20T00:00:00+00:00 [running]> on host ef71d3f52879
[2023-07-22T05:56:59.310+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=is_api_available
AIRFLOW_CTX_EXECUTION_DATE=2023-07-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-07-20T00:00:00+00:00
[2023-07-22T05:56:59.313+0000] {http.py:120} INFO - Poking: api/
[2023-07-22T05:56:59.328+0000] {base.py:71} INFO - Using connection ID 'user_api' for task execution.
[2023-07-22T05:56:59.333+0000] {http.py:148} INFO - Sending 'GET' to url: https://randomuser.me/api/
[2023-07-22T05:57:00.302+0000] {base.py:213} INFO - Success criteria met. Exiting.
[2023-07-22T05:57:00.351+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=is_api_available, execution_date=20230720T000000, start_date=20230722T055659, end_date=20230722T055700
[2023-07-22T05:57:00.459+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2023-07-22T05:57:00.609+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
